{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d46260b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_community'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SystemMessage, HumanMessage\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtavily_search\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TavilySearchResults\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_community'"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import operator\n",
    "import os\n",
    "import re\n",
    "from datetime import date, datetime, timedelta\n",
    "from pathlib import Path\n",
    "from typing import TypedDict, List, Optional, Literal, Annotated\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7964d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1) Schemas\n",
    "# -----------------------------\n",
    "class Task(BaseModel):\n",
    "    id: int\n",
    "    title: str\n",
    "\n",
    "    goal: str = Field(\n",
    "        ...,\n",
    "        description=\"One sentence describing what the reader should be able to do/understand after this section.\",\n",
    "    )\n",
    "    bullets: List[str] = Field(\n",
    "        ...,\n",
    "        min_length=3,\n",
    "        max_length=6,\n",
    "        description=\"3–6 concrete, non-overlapping subpoints to cover in this section.\",\n",
    "    )\n",
    "    target_words: int = Field(..., description=\"Target word count for this section (120–550).\")\n",
    "\n",
    "    tags: List[str] = Field(default_factory=list)\n",
    "    requires_research: bool = False\n",
    "    requires_citations: bool = False\n",
    "    requires_code: bool = False\n",
    "\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    blog_title: str\n",
    "    audience: str\n",
    "    tone: str\n",
    "\n",
    "    # NEW: tells workers what genre this is (prevents drift)\n",
    "    blog_kind: Literal[\"explainer\", \"tutorial\", \"news_roundup\", \"comparison\", \"system_design\"] = \"explainer\"\n",
    "\n",
    "    constraints: List[str] = Field(default_factory=list)\n",
    "    tasks: List[Task]\n",
    "\n",
    "\n",
    "class EvidenceItem(BaseModel):\n",
    "    title: str\n",
    "    url: str\n",
    "    published_at: Optional[str] = None  # prefer ISO \"YYYY-MM-DD\"\n",
    "    snippet: Optional[str] = None\n",
    "    source: Optional[str] = None\n",
    "\n",
    "\n",
    "class RouterDecision(BaseModel):\n",
    "    needs_research: bool\n",
    "    mode: Literal[\"closed_book\", \"hybrid\", \"open_book\"]\n",
    "    reason: str\n",
    "    queries: List[str] = Field(default_factory=list)\n",
    "    max_results_per_query: int = Field(5, description=\"How many results to fetch per query (3–8).\")\n",
    "\n",
    "\n",
    "class EvidencePack(BaseModel):\n",
    "    evidence: List[EvidenceItem] = Field(default_factory=list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e00b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    topic: str\n",
    "\n",
    "    # routing / research\n",
    "    mode: str\n",
    "    needs_research: bool\n",
    "    queries: List[str]\n",
    "    evidence: List[EvidenceItem]\n",
    "    plan: Optional[Plan]\n",
    "\n",
    "    # NEW: recency control\n",
    "    as_of: str           # ISO date, e.g. \"2026-01-29\"\n",
    "    recency_days: int    # 7 for weekly news, 30 for hybrid, etc.\n",
    "\n",
    "    # workers\n",
    "    sections: Annotated[List[tuple[int, str]], operator.add]  # (task_id, section_md)\n",
    "    final: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd530b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 2) LLM\n",
    "# -----------------------------\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e1cc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 3) Router (decide upfront)\n",
    "# -----------------------------\n",
    "ROUTER_SYSTEM = \"\"\"You are a routing module for a technical blog planner.\n",
    "\n",
    "Decide whether web research is needed BEFORE planning.\n",
    "\n",
    "Modes:\n",
    "- closed_book (needs_research=false):\n",
    "  Evergreen topics where correctness does not depend on recent facts (concepts, fundamentals).\n",
    "- hybrid (needs_research=true):\n",
    "  Mostly evergreen but needs up-to-date examples/tools/models to be useful.\n",
    "- open_book (needs_research=true):\n",
    "  Mostly volatile: weekly roundups, \"this week\", \"latest\", rankings, pricing, policy/regulation.\n",
    "\n",
    "If needs_research=true:\n",
    "- Output 3–10 high-signal queries.\n",
    "- Queries should be scoped and specific (avoid generic queries like just \"AI\" or \"LLM\").\n",
    "- For open_book weekly roundup, include queries that reflect the last 7 days constraint.\n",
    "\"\"\"\n",
    "\n",
    "def router_node(state: State) -> dict:\n",
    "    topic = state[\"topic\"]\n",
    "    decider = llm.with_structured_output(RouterDecision)\n",
    "    decision = decider.invoke(\n",
    "        [\n",
    "            SystemMessage(content=ROUTER_SYSTEM),\n",
    "            HumanMessage(content=f\"Topic: {topic}\\nAs-of date: {state['as_of']}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Set default recency window based on mode\n",
    "    if decision.mode == \"open_book\":\n",
    "        recency_days = 7\n",
    "    elif decision.mode == \"hybrid\":\n",
    "        recency_days = 45\n",
    "    else:\n",
    "        recency_days = 3650\n",
    "\n",
    "    return {\n",
    "        \"needs_research\": decision.needs_research,\n",
    "        \"mode\": decision.mode,\n",
    "        \"queries\": decision.queries,\n",
    "        \"recency_days\": recency_days,\n",
    "    }\n",
    "\n",
    "def route_next(state: State) -> str:\n",
    "    return \"research\" if state[\"needs_research\"] else \"orchestrator\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c69df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 4) Research (Tavily)\n",
    "# -----------------------------\n",
    "def _tavily_search(query: str, max_results: int = 5) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Uses TavilySearchResults if installed and TAVILY_API_KEY is set.\n",
    "    Returns list of dict with common fields. Note: published date is often missing.\n",
    "    \"\"\"\n",
    "    tool = TavilySearchResults(max_results=max_results)\n",
    "    results = tool.invoke({\"query\": query})\n",
    "\n",
    "    normalized: List[dict] = []\n",
    "    for r in results or []:\n",
    "        normalized.append(\n",
    "            {\n",
    "                \"title\": r.get(\"title\") or \"\",\n",
    "                \"url\": r.get(\"url\") or \"\",\n",
    "                \"snippet\": r.get(\"content\") or r.get(\"snippet\") or \"\",\n",
    "                \"published_at\": r.get(\"published_date\") or r.get(\"published_at\"),\n",
    "                \"source\": r.get(\"source\"),\n",
    "            }\n",
    "        )\n",
    "    return normalized\n",
    "\n",
    "\n",
    "def _iso_to_date(s: Optional[str]) -> Optional[date]:\n",
    "    if not s:\n",
    "        return None\n",
    "    try:\n",
    "        return date.fromisoformat(s[:10])\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "RESEARCH_SYSTEM = \"\"\"You are a research synthesizer for technical writing.\n",
    "\n",
    "Given raw web search results, produce a deduplicated list of EvidenceItem objects.\n",
    "\n",
    "Rules:\n",
    "- Only include items with a non-empty url.\n",
    "- Prefer relevant + authoritative sources (company blogs, docs, reputable outlets).\n",
    "- Extract/normalize published_at as ISO (YYYY-MM-DD) if you can infer it from title/snippet.\n",
    "  If you can't infer a date reliably, set published_at=null (do NOT guess).\n",
    "- Keep snippets short.\n",
    "- Deduplicate by URL.\n",
    "\"\"\"\n",
    "\n",
    "def research_node(state: State) -> dict:\n",
    "    queries = (state.get(\"queries\", []) or [])[:10]\n",
    "    max_results = 6\n",
    "\n",
    "    raw_results: List[dict] = []\n",
    "    for q in queries:\n",
    "        raw_results.extend(_tavily_search(q, max_results=max_results))\n",
    "\n",
    "    if not raw_results:\n",
    "        return {\"evidence\": []}\n",
    "\n",
    "    extractor = llm.with_structured_output(EvidencePack)\n",
    "    pack = extractor.invoke(\n",
    "        [\n",
    "            SystemMessage(content=RESEARCH_SYSTEM),\n",
    "            HumanMessage(\n",
    "                content=(\n",
    "                    f\"As-of date: {state['as_of']}\\n\"\n",
    "                    f\"Recency days: {state['recency_days']}\\n\\n\"\n",
    "                    f\"Raw results:\\n{raw_results}\"\n",
    "                )\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Deduplicate by URL\n",
    "    dedup = {}\n",
    "    for e in pack.evidence:\n",
    "        if e.url:\n",
    "            dedup[e.url] = e\n",
    "    evidence = list(dedup.values())\n",
    "\n",
    "    # HARD RECENCY FILTER for open_book weekly roundup:\n",
    "    # keep only items with a parseable ISO date and within the window.\n",
    "    mode = state.get(\"mode\", \"closed_book\")\n",
    "    if mode == \"open_book\":\n",
    "        as_of = date.fromisoformat(state[\"as_of\"])\n",
    "        cutoff = as_of - timedelta(days=int(state[\"recency_days\"]))\n",
    "        fresh: List[EvidenceItem] = []\n",
    "        for e in evidence:\n",
    "            d = _iso_to_date(e.published_at)\n",
    "            if d and d >= cutoff:\n",
    "                fresh.append(e)\n",
    "        evidence = fresh\n",
    "\n",
    "    return {\"evidence\": evidence}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06809f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 5) Orchestrator (Plan)\n",
    "# -----------------------------\n",
    "ORCH_SYSTEM = \"\"\"You are a senior technical writer and developer advocate.\n",
    "Your job is to produce a highly actionable outline for a technical blog post.\n",
    "\n",
    "Hard requirements:\n",
    "- Create 5–9 sections (tasks) suitable for the topic and audience.\n",
    "- Each task must include:\n",
    "  1) goal (1 sentence)\n",
    "  2) 3–6 bullets that are concrete, specific, and non-overlapping\n",
    "  3) target word count (120–550)\n",
    "\n",
    "Flexibility:\n",
    "- Do NOT use a fixed taxonomy unless it naturally fits.\n",
    "- You may tag tasks (tags field), but tags are flexible.\n",
    "\n",
    "Quality bar:\n",
    "- Assume the reader is a developer; use correct terminology.\n",
    "- Bullets must be actionable: build/compare/measure/verify/debug.\n",
    "- Ensure the overall plan includes at least 2 of these somewhere:\n",
    "  * minimal code sketch / MWE (set requires_code=True for that section)\n",
    "  * edge cases / failure modes\n",
    "  * performance/cost considerations\n",
    "  * security/privacy considerations (if relevant)\n",
    "  * debugging/observability tips\n",
    "\n",
    "Grounding rules:\n",
    "- Mode closed_book: keep it evergreen; do not depend on evidence.\n",
    "- Mode hybrid:\n",
    "  - Use evidence for up-to-date examples (models/tools/releases) in bullets.\n",
    "  - Mark sections using fresh info as requires_research=True and requires_citations=True.\n",
    "- Mode open_book (weekly news roundup):\n",
    "  - Set blog_kind = \"news_roundup\".\n",
    "  - Every section is about summarizing events + implications.\n",
    "  - DO NOT include tutorial/how-to sections (no scraping/RSS/how to fetch news) unless user explicitly asked for that.\n",
    "  - If evidence is empty or insufficient, create a plan that transparently says \"insufficient fresh sources\"\n",
    "    and includes only what can be supported.\n",
    "\n",
    "Output must strictly match the Plan schema.\n",
    "\"\"\"\n",
    "\n",
    "def orchestrator_node(state: State) -> dict:\n",
    "    planner = llm.with_structured_output(Plan)\n",
    "    evidence = state.get(\"evidence\", [])\n",
    "    mode = state.get(\"mode\", \"closed_book\")\n",
    "\n",
    "    # Force blog_kind for open_book\n",
    "    forced_kind = \"news_roundup\" if mode == \"open_book\" else None\n",
    "\n",
    "    plan = planner.invoke(\n",
    "        [\n",
    "            SystemMessage(content=ORCH_SYSTEM),\n",
    "            HumanMessage(\n",
    "                content=(\n",
    "                    f\"Topic: {state['topic']}\\n\"\n",
    "                    f\"Mode: {mode}\\n\"\n",
    "                    f\"As-of: {state['as_of']} (recency_days={state['recency_days']})\\n\"\n",
    "                    f\"{'Force blog_kind=news_roundup' if forced_kind else ''}\\n\\n\"\n",
    "                    f\"Evidence (ONLY use for fresh claims; may be empty):\\n\"\n",
    "                    f\"{[e.model_dump() for e in evidence][:16]}\\n\\n\"\n",
    "                    f\"Instruction: If mode=open_book, your plan must NOT drift into a tutorial.\"\n",
    "                )\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Ensure open_book forces the kind even if model forgets\n",
    "    if forced_kind:\n",
    "        plan.blog_kind = \"news_roundup\"\n",
    "\n",
    "    return {\"plan\": plan}\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Fanout\n",
    "# -----------------------------\n",
    "def fanout(state: State):\n",
    "    assert state[\"plan\"] is not None\n",
    "    return [\n",
    "        Send(\n",
    "            \"worker\",\n",
    "            {\n",
    "                \"task\": task.model_dump(),\n",
    "                \"topic\": state[\"topic\"],\n",
    "                \"mode\": state[\"mode\"],\n",
    "                \"as_of\": state[\"as_of\"],\n",
    "                \"recency_days\": state[\"recency_days\"],\n",
    "                \"plan\": state[\"plan\"].model_dump(),\n",
    "                \"evidence\": [e.model_dump() for e in state.get(\"evidence\", [])],\n",
    "            },\n",
    "        )\n",
    "        for task in state[\"plan\"].tasks\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f50a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 7) Worker (write one section)\n",
    "# -----------------------------\n",
    "WORKER_SYSTEM = \"\"\"You are a senior technical writer and developer advocate.\n",
    "Write ONE section of a technical blog post in Markdown.\n",
    "\n",
    "Hard constraints:\n",
    "- Follow the provided Goal and cover ALL Bullets in order (do not skip or merge bullets).\n",
    "- Stay close to Target words (±15%).\n",
    "- Output ONLY the section content in Markdown (no blog title H1, no extra commentary).\n",
    "- Start with a '## <Section Title>' heading.\n",
    "\n",
    "Scope guard (prevents mid-blog topic drift):\n",
    "- If blog_kind == \"news_roundup\": do NOT turn this into a tutorial/how-to guide.\n",
    "  Do NOT teach web scraping, RSS, automation, or \"how to fetch news\" unless bullets explicitly ask for it.\n",
    "  Focus on summarizing events and implications.\n",
    "\n",
    "Grounding policy:\n",
    "- If mode == open_book (weekly news):\n",
    "  - Do NOT introduce any specific event/company/model/funding/policy claim unless it is supported by provided Evidence URLs.\n",
    "  - For each event claim, attach a source as a Markdown link: ([Source](URL)).\n",
    "  - Only use URLs provided in Evidence. If not supported, write: \"Not found in provided sources.\"\n",
    "- If requires_citations == true (hybrid sections):\n",
    "  - For outside-world claims, cite Evidence URLs the same way.\n",
    "- Evergreen reasoning (concepts, intuition) is OK without citations unless requires_citations is true.\n",
    "\n",
    "Code:\n",
    "- If requires_code == true, include at least one minimal, correct code snippet relevant to the bullets.\n",
    "\n",
    "Style:\n",
    "- Short paragraphs, bullets where helpful, code fences for code.\n",
    "- Avoid fluff/marketing. Be precise and implementation-oriented.\n",
    "\"\"\"\n",
    "\n",
    "def worker_node(payload: dict) -> dict:\n",
    "    \n",
    "    task = Task(**payload[\"task\"])\n",
    "    plan = Plan(**payload[\"plan\"])\n",
    "    evidence = [EvidenceItem(**e) for e in payload.get(\"evidence\", [])]\n",
    "    topic = payload[\"topic\"]\n",
    "    mode = payload.get(\"mode\", \"closed_book\")\n",
    "    as_of = payload.get(\"as_of\")\n",
    "    recency_days = payload.get(\"recency_days\")\n",
    "\n",
    "    bullets_text = \"\\n- \" + \"\\n- \".join(task.bullets)\n",
    "\n",
    "    # Provide a compact evidence list for citation use\n",
    "    evidence_text = \"\"\n",
    "    if evidence:\n",
    "        evidence_text = \"\\n\".join(\n",
    "            f\"- {e.title} | {e.url} | {e.published_at or 'date:unknown'}\".strip()\n",
    "            for e in evidence[:20]\n",
    "        )\n",
    "\n",
    "    section_md = llm.invoke(\n",
    "        [\n",
    "            SystemMessage(content=WORKER_SYSTEM),\n",
    "            HumanMessage(\n",
    "                content=(\n",
    "                    f\"Blog title: {plan.blog_title}\\n\"\n",
    "                    f\"Audience: {plan.audience}\\n\"\n",
    "                    f\"Tone: {plan.tone}\\n\"\n",
    "                    f\"Blog kind: {plan.blog_kind}\\n\"\n",
    "                    f\"Constraints: {plan.constraints}\\n\"\n",
    "                    f\"Topic: {topic}\\n\"\n",
    "                    f\"Mode: {mode}\\n\"\n",
    "                    f\"As-of: {as_of} (recency_days={recency_days})\\n\\n\"\n",
    "                    f\"Section title: {task.title}\\n\"\n",
    "                    f\"Goal: {task.goal}\\n\"\n",
    "                    f\"Target words: {task.target_words}\\n\"\n",
    "                    f\"Tags: {task.tags}\\n\"\n",
    "                    f\"requires_research: {task.requires_research}\\n\"\n",
    "                    f\"requires_citations: {task.requires_citations}\\n\"\n",
    "                    f\"requires_code: {task.requires_code}\\n\"\n",
    "                    f\"Bullets:{bullets_text}\\n\\n\"\n",
    "                    f\"Evidence (ONLY use these URLs when citing):\\n{evidence_text}\\n\"\n",
    "                )\n",
    "            ),\n",
    "        ]\n",
    "    ).content.strip()\n",
    "\n",
    "    # deterministic ordering\n",
    "    return {\"sections\": [(task.id, section_md)]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f45bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 8) Reducer (merge + save)\n",
    "# -----------------------------\n",
    "def reducer_node(state: State) -> dict:\n",
    "    plan = state[\"plan\"]\n",
    "    if plan is None:\n",
    "        raise ValueError(\"Reducer called without a plan.\")\n",
    "\n",
    "    ordered_sections = [md for _, md in sorted(state[\"sections\"], key=lambda x: x[0])]\n",
    "    body = \"\\n\\n\".join(ordered_sections).strip()\n",
    "    final_md = f\"# {plan.blog_title}\\n\\n{body}\\n\"\n",
    "\n",
    "    filename = f\"{plan.blog_title}.md\"\n",
    "    Path(filename).write_text(final_md, encoding=\"utf-8\")\n",
    "\n",
    "    return {\"final\": final_md}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adfb355c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'State' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# 9) Build graph\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m g = StateGraph(\u001b[43mState\u001b[49m)\n\u001b[32m      5\u001b[39m g.add_node(\u001b[33m\"\u001b[39m\u001b[33mrouter\u001b[39m\u001b[33m\"\u001b[39m, router_node)\n\u001b[32m      6\u001b[39m g.add_node(\u001b[33m\"\u001b[39m\u001b[33mresearch\u001b[39m\u001b[33m\"\u001b[39m, research_node)\n",
      "\u001b[31mNameError\u001b[39m: name 'State' is not defined"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 9) Build graph\n",
    "# -----------------------------\n",
    "g = StateGraph(State)\n",
    "g.add_node(\"router\", router_node)\n",
    "g.add_node(\"research\", research_node)\n",
    "g.add_node(\"orchestrator\", orchestrator_node)\n",
    "g.add_node(\"worker\", worker_node)\n",
    "g.add_node(\"reducer\", reducer_node)\n",
    "\n",
    "g.add_edge(START, \"router\")\n",
    "g.add_conditional_edges(\"router\", route_next, {\"research\": \"research\", \"orchestrator\": \"orchestrator\"})\n",
    "g.add_edge(\"research\", \"orchestrator\")\n",
    "\n",
    "g.add_conditional_edges(\"orchestrator\", fanout, [\"worker\"])\n",
    "g.add_edge(\"worker\", \"reducer\")\n",
    "g.add_edge(\"reducer\", END)\n",
    "\n",
    "app = g.compile()\n",
    "\n",
    "app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "430f5bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 10) Runner\n",
    "# -----------------------------\n",
    "def run(topic: str, as_of: Optional[str] = None):\n",
    "    if as_of is None:\n",
    "        as_of = date.today().isoformat()\n",
    "\n",
    "    out = app.invoke(\n",
    "        {\n",
    "            \"topic\": topic,\n",
    "            \"mode\": \"\",\n",
    "            \"needs_research\": False,\n",
    "            \"queries\": [],\n",
    "            \"evidence\": [],\n",
    "            \"plan\": None,\n",
    "            \"as_of\": as_of,\n",
    "            \"recency_days\": 7,   # router may overwrite\n",
    "            \"sections\": [],\n",
    "            \"final\": \"\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    plan: Plan = out[\"plan\"]\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"TOPIC:\", topic)\n",
    "    print(\"AS_OF:\", out.get(\"as_of\"), \"RECENCY_DAYS:\", out.get(\"recency_days\"))\n",
    "    print(\"MODE:\", out.get(\"mode\"))\n",
    "    print(\"BLOG_KIND:\", plan.blog_kind)\n",
    "    print(\"NEEDS_RESEARCH:\", out.get(\"needs_research\"))\n",
    "    print(\"QUERIES:\", (out.get(\"queries\") or [])[:6])\n",
    "    print(\"EVIDENCE_COUNT:\", len(out.get(\"evidence\", [])))\n",
    "    if out.get(\"evidence\"):\n",
    "        print(\"EVIDENCE_SAMPLE:\", [e.model_dump() for e in out[\"evidence\"][:2]])\n",
    "    print(\"TASKS:\", len(plan.tasks))\n",
    "    print(\"SAVED_MD_CHARS:\", len(out.get(\"final\", \"\")))\n",
    "    print(\"=\" * 100 + \"\\n\")\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5be9f123",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'app' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWrite a blog on Self Attention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(topic, as_of)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m as_of \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      6\u001b[39m     as_of = date.today().isoformat()\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m out = \u001b[43mapp\u001b[49m.invoke(\n\u001b[32m      9\u001b[39m     {\n\u001b[32m     10\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtopic\u001b[39m\u001b[33m\"\u001b[39m: topic,\n\u001b[32m     11\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mneeds_research\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     13\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mqueries\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m     14\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mevidence\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m     15\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mplan\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     16\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas_of\u001b[39m\u001b[33m\"\u001b[39m: as_of,\n\u001b[32m     17\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrecency_days\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m7\u001b[39m,   \u001b[38;5;66;03m# router may overwrite\u001b[39;00m\n\u001b[32m     18\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msections\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m     19\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfinal\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     20\u001b[39m     }\n\u001b[32m     21\u001b[39m )\n\u001b[32m     23\u001b[39m plan: Plan = out[\u001b[33m\"\u001b[39m\u001b[33mplan\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m100\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'app' is not defined"
     ]
    }
   ],
   "source": [
    "run(\"Write a blog on Self Attention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18b4d07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
